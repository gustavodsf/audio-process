{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-24T19:36:37.880704Z",
     "iopub.status.busy": "2020-08-24T19:36:37.880443Z",
     "iopub.status.idle": "2020-08-24T19:36:37.885267Z",
     "shell.execute_reply": "2020-08-24T19:36:37.883793Z",
     "shell.execute_reply.started": "2020-08-24T19:36:37.880675Z"
    }
   },
   "source": [
    "### Código Compartilhado\n",
    "> Notebook utilizado para código que é compartilhado por diferentes notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-24T20:09:57.257398Z",
     "iopub.status.busy": "2020-08-24T20:09:57.257128Z",
     "iopub.status.idle": "2020-08-24T20:09:57.262013Z",
     "shell.execute_reply": "2020-08-24T20:09:57.260606Z",
     "shell.execute_reply.started": "2020-08-24T20:09:57.257374Z"
    }
   },
   "source": [
    "* Import das bibliotecas mais utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-21T12:55:24.822555Z",
     "iopub.status.busy": "2020-09-21T12:55:24.822267Z",
     "iopub.status.idle": "2020-09-21T12:55:26.360619Z",
     "shell.execute_reply": "2020-09-21T12:55:26.359762Z",
     "shell.execute_reply.started": "2020-09-21T12:55:24.822531Z"
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from math import floor, ceil\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "\n",
    "import sys  \n",
    "sys.path.insert(0, '/Users/gustavofigueiredo/projects/ml-beat-box/audio_classify/src/')\n",
    "from mel_features import log_mel_spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Contantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T17:01:54.975177Z",
     "iopub.status.busy": "2020-09-17T17:01:54.974885Z",
     "iopub.status.idle": "2020-09-17T17:01:54.979264Z",
     "shell.execute_reply": "2020-09-17T17:01:54.978387Z",
     "shell.execute_reply.started": "2020-09-17T17:01:54.975149Z"
    }
   },
   "outputs": [],
   "source": [
    "LABEL = [\"music\",\"not_music\"]\n",
    "MODEL_PATH = '../model/'\n",
    "SAMPLE_RATE = 22050\n",
    "HOP_LENGTH = 512\n",
    "FRAME_LENGTH = 2048\n",
    "BPM_RATE = 120\n",
    "F_MFCC = 13\n",
    "SEGMENT_DURATION = 3\n",
    "N_MELS=32\n",
    "SAMPLES_PER_SEGMENT = SAMPLE_RATE * SEGMENT_DURATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-02T01:13:22.259016Z",
     "iopub.status.busy": "2020-09-02T01:13:22.258751Z",
     "iopub.status.idle": "2020-09-02T01:13:22.263483Z",
     "shell.execute_reply": "2020-09-02T01:13:22.262379Z",
     "shell.execute_reply.started": "2020-09-02T01:13:22.258992Z"
    }
   },
   "source": [
    "* Algumas funções que são reutilizáveis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Código que encapsula o gráfico do formato da onda de um sinal enviado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_wave_plot(audio):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    librosa.display.waveplot(audio, sr=SAMPLE_RATE)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Código que serve para geração das fetuares baseadas em croma e ao mesmo tempo gerar o gráfico para permitir sua visualização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_chroma_plot(audio):\n",
    "    chromagram = librosa.feature.chroma_cqt(y=audio, sr=SAMPLE_RATE, hop_length=HOP_LENGTH)\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    librosa.display.specshow(chromagram, x_axis='time', y_axis='chroma', hop_length=HOP_LENGTH, cmap='coolwarm')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Código que serve para geração das fetuares baseadas em energia e ao mesmo tempo gerar o gráfico para permitir sua visualização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_energy_plot(audio):\n",
    "    rms = librosa.feature.rms(y=audio, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH, center=True)\n",
    "    rms = rms[0]\n",
    "    energy = np.array([sum(abs(audio[i:i+FRAME_LENGTH]**2)) for i in range(0, len(audio+1), HOP_LENGTH) ])\n",
    "    frames = range(len(energy))\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    t = librosa.frames_to_time(frames, sr=SAMPLE_RATE, hop_length=HOP_LENGTH)\n",
    "    librosa.display.waveplot(audio, sr=SAMPLE_RATE, alpha=0.4)\n",
    "    plt.plot(t, energy/energy.max(), 'r--')             # normalized for visualization\n",
    "    frames = range(len(rms))\n",
    "    t = librosa.frames_to_time(frames, sr=SAMPLE_RATE, hop_length=HOP_LENGTH)\n",
    "    plt.plot(t, rms/rms.max(), color='g') # normalized for visualization\n",
    "    plt.legend(('Energy', 'RMSE'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Código que serve para geração das fetuares baseadas em croma e ao mesmo tempo gerar o gráfico para permitir sua visualização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_beat_track_plot(audio):\n",
    "    onset_env = librosa.onset.onset_strength(y=audio, sr=SAMPLE_RATE)\n",
    "    tempo, beats = librosa.beat.beat_track(onset_envelope=onset_env)\n",
    "    times = librosa.times_like(onset_env, sr=SAMPLE_RATE)\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(times, librosa.util.normalize(onset_env), label='Onset strength')\n",
    "    plt.vlines(times[beats], 0, 1, alpha=0.5, color='r', linestyle='--', label='Beats')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-02T01:39:02.758947Z",
     "iopub.status.busy": "2020-09-02T01:39:02.758625Z",
     "iopub.status.idle": "2020-09-02T01:39:02.762801Z",
     "shell.execute_reply": "2020-09-02T01:39:02.761913Z",
     "shell.execute_reply.started": "2020-09-02T01:39:02.758923Z"
    }
   },
   "source": [
    "> Código que serve para geração das fetuares baseadas em plp e ao mesmo tempo gerar o gráfico para permitir sua visualização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_plp_plot(audio):\n",
    "    onset_env = librosa.onset.onset_strength(y=audio, sr=SAMPLE_RATE)\n",
    "    pulse = librosa.beat.plp(onset_envelope=onset_env, sr=SAMPLE_RATE)\n",
    "    beats_plp = np.flatnonzero(librosa.util.localmax(pulse))\n",
    "    times = librosa.times_like(pulse, sr=SAMPLE_RATE)\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(times, librosa.util.normalize(pulse), label='PLP')\n",
    "    plt.vlines(times[beats_plp], 0, 1, alpha=0.5, color='r', linestyle='--', label='PLP Beats')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-02T01:41:55.335950Z",
     "iopub.status.busy": "2020-09-02T01:41:55.335683Z",
     "iopub.status.idle": "2020-09-02T01:41:55.340484Z",
     "shell.execute_reply": "2020-09-02T01:41:55.339179Z",
     "shell.execute_reply.started": "2020-09-02T01:41:55.335927Z"
    }
   },
   "source": [
    "> Código que serve para geração das fetuares baseadas em MFCC e ao mesmo tempo gerar o gráfico para permitir sua visualização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_mfcc_plot(audio):\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    mfccs = librosa.feature.mfcc(audio, sr=SAMPLE_RATE)\n",
    "    scaler = MinMaxScaler()\n",
    "    mfccs = scaler.fit_transform(mfccs)\n",
    "    librosa.display.specshow(mfccs, sr=SAMPLE_RATE, x_axis='time')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Código que serve para geração das fetuares baseadas energia e ao mesmo tempo gerar o gráfico para permitir sua visualização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_novelty_energy_plot(audio):\n",
    "    rmse = librosa.feature.rms(audio, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH).flatten()\n",
    "    rmse_diff = np.zeros_like(rmse)\n",
    "    rmse_diff[1:] = np.diff(rmse)\n",
    "    energy_novelty = np.max([np.zeros_like(rmse_diff), rmse_diff], axis=0)\n",
    "    frames = np.arange(len(rmse))\n",
    "    t = librosa.frames_to_time(frames, sr=SAMPLE_RATE)\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(t, rmse, 'b--', t, rmse_diff, 'g--^', t, energy_novelty, 'r-')\n",
    "    plt.xlim(0, t.max())\n",
    "    plt.xlabel('Time (sec)')\n",
    "    plt.legend(('RMSE', 'delta RMSE', 'energy novelty')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-02T01:41:00.491026Z",
     "iopub.status.busy": "2020-09-02T01:41:00.490754Z",
     "iopub.status.idle": "2020-09-02T01:41:00.495379Z",
     "shell.execute_reply": "2020-09-02T01:41:00.494268Z",
     "shell.execute_reply.started": "2020-09-02T01:41:00.491002Z"
    }
   },
   "source": [
    "> Código que serve para geração das fetuares baseado no spectral centroid e ao mesmo tempo gerar o gráfico para permitir sua visualização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, axis=0):\n",
    "    return sklearn.preprocessing.minmax_scale(x, axis=axis)\n",
    "\n",
    "def my_spectral_centroid_plot(audio):\n",
    "    spectral_centroids = librosa.feature.spectral_centroid(audio+0.01, sr=SAMPLE_RATE)[0]\n",
    "    frames = range(len(spectral_centroids))\n",
    "    t = librosa.frames_to_time(frames)\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    librosa.display.waveplot(audio, sr=SAMPLE_RATE, alpha=0.4)\n",
    "    plt.plot(t, normalize(spectral_centroids), color='r') # normalize for visualization purposes\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-02T01:39:31.224360Z",
     "iopub.status.busy": "2020-09-02T01:39:31.224084Z",
     "iopub.status.idle": "2020-09-02T01:39:31.229379Z",
     "shell.execute_reply": "2020-09-02T01:39:31.228145Z",
     "shell.execute_reply.started": "2020-09-02T01:39:31.224336Z"
    }
   },
   "source": [
    "> Código que serve para geração das fetuares baseadas em zero crossing rate e ao mesmo tempo gerar o gráfico para permitir sua visualização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_zero_cross_plot(audio):\n",
    "    zcrs = librosa.feature.zero_crossing_rate(audio + 0.0001)[0]\n",
    "    zcrs_diff = np.zeros_like(zcrs)\n",
    "    zcrs_diff[1:] = np.diff(zcrs)\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    plt.plot(zcrs)\n",
    "    plt.plot(zcrs_diff)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-02T01:53:36.194477Z",
     "iopub.status.busy": "2020-09-02T01:53:36.194256Z",
     "iopub.status.idle": "2020-09-02T01:53:36.197896Z",
     "shell.execute_reply": "2020-09-02T01:53:36.196986Z",
     "shell.execute_reply.started": "2020-09-02T01:53:36.194458Z"
    }
   },
   "source": [
    "> Código para converter a entrada no formato da entrada do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-02T02:00:16.334071Z",
     "iopub.status.busy": "2020-09-02T02:00:16.333794Z",
     "iopub.status.idle": "2020-09-02T02:00:16.344285Z",
     "shell.execute_reply": "2020-09-02T02:00:16.343311Z",
     "shell.execute_reply.started": "2020-09-02T02:00:16.334046Z"
    }
   },
   "outputs": [],
   "source": [
    "def _generate_mfcc(filtered_signal):\n",
    "    mfcc = librosa.feature.mfcc(filtered_signal, \n",
    "                                sr = SAMPLE_RATE,\n",
    "                                n_mfcc=F_MFCC,\n",
    "                                n_fft=FRAME_LENGTH,\n",
    "                                hop_length=HOP_LENGTH)\n",
    "    return mfcc\n",
    "\n",
    "def _generate_rms(filtered_signal):\n",
    "    rms = librosa.feature.rms(y=filtered_signal, \n",
    "                              frame_length=SAMPLE_RATE, \n",
    "                              hop_length=HOP_LENGTH, \n",
    "                              center=True)\n",
    "    return rms\n",
    "\n",
    "def _generate_spectral_centroid(filtered_signal):\n",
    "    centroid = librosa.feature.spectral_centroid(filtered_signal+0.01, \n",
    "                                                 sr=SAMPLE_RATE)\n",
    "    return centroid\n",
    "\n",
    "def _generate_zero_crossing_rate(filtered_signal):\n",
    "    zcr = librosa.feature.zero_crossing_rate(y=filtered_signal + 0.01)\n",
    "    return zcr\n",
    "\n",
    "def _generate_onset_strength(filtered_signal):\n",
    "    onset = librosa.onset.onset_strength(y=filtered_signal, \n",
    "        sr=SAMPLE_RATE)\n",
    "    onset = onset[np.newaxis, ...]\n",
    "    return onset\n",
    "\n",
    "def _generate_mel_spectogram(filtered_signal, version):\n",
    "    if version == \"normal\":\n",
    "        mel = librosa.feature.melspectrogram(y=filtered_signal, \n",
    "                                             sr=SAMPLE_RATE, \n",
    "                                             n_mels=N_MELS, \n",
    "                                             fmax=10000 , \n",
    "                                             n_fft=FRAME_LENGTH, \n",
    "                                             hop_length=HOP_LENGTH)\n",
    "    else:\n",
    "        mel = log_mel_spectrogram(filtered_signal, audio_sample_rate=SAMPLE_RATE, log_offset=0.01)\n",
    "    return mel\n",
    "\n",
    "def generate_input(signal, list_of_features, version):\n",
    "    num_segments = floor(len(signal)/SAMPLES_PER_SEGMENT)\n",
    "    samples = []\n",
    "    \n",
    "    # process all segments of audio file\n",
    "    for d in range(num_segments):\n",
    "        # calculate start and finish sample for current segment\n",
    "        start = SAMPLES_PER_SEGMENT * d\n",
    "        finish = start + SAMPLES_PER_SEGMENT\n",
    "        filtered_signal =  signal[start:finish]\n",
    "        \n",
    "        features = {\n",
    "            \"centroid\": _generate_spectral_centroid(filtered_signal),\n",
    "            \"mfcc\": _generate_mfcc(filtered_signal),\n",
    "            \"mel_spec\": _generate_mel_spectogram(filtered_signal, version),\n",
    "            \"onset\": _generate_onset_strength(filtered_signal),\n",
    "            \"rms\": _generate_rms(filtered_signal),\n",
    "            \"zcr\": _generate_zero_crossing_rate(filtered_signal)\n",
    "        }\n",
    "        \n",
    "        f1 = features[list_of_features[0]]\n",
    "        for i in range(1, len(list_of_features)):\n",
    "            f_other = features[list_of_features[i]]\n",
    "            f1 = np.concatenate([f1, f_other], axis = 0)\n",
    "        samples.append(f1.T)\n",
    "    samples = np.array(samples) \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Código para rodar o modelo treinado de acordo com as features selecionadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(features, test_file, suffix=[], version=\"normal\"):\n",
    "    model = keras.models.load_model('../model/mlp_beat_box_{}'.format(\"_\".join(features + suffix)))\n",
    "    intro_signal, _ = librosa.load(test_file, sr=SAMPLE_RATE)\n",
    "    f_input = generate_input(intro_signal, features, version)\n",
    "    X = f_input[..., np.newaxis] \n",
    "    import warnings\n",
    "    print(\"SAMPLE SHAPE: {}\".format(X.shape))\n",
    "    warnings.filterwarnings('ignore')\n",
    "    prediction = model.predict(X)\n",
    "    predicted_index = np.argmax(prediction, axis=1)\n",
    "    pLabel = list(map(lambda x: LABEL[x] ,predicted_index))\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(pLabel)\n",
    "    plt.show()\n",
    "    del model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
